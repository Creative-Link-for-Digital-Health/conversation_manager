# Research Scenario Configuration
# This file defines the experimental setup for this research session

[scenario]
name = "Conversation Analysis Research"
description = "Experimental setup for studying conversation patterns with AI assistants"
version = "1.0.0"
created_date = "2025-05-24"
scenario_id = "150a8400-e39g-42d3-b7x6-q49653441020"

[llm_provider]
# Single LLM provider configuration
name = "openai"
secrets_key = "OPENAI"  # Key prefix in .secrets.toml
model = "gpt-4"
temperature = 0.7
max_tokens = 1000    # Current max for most models is 4096
description = "OpenAI's GPT-4 model"

[system_prompt]
# Reference to prompt stored in prompt database
prompt_id = "550e8400-e29b-41d4-a716-446655440000"

[logging]
# Conversation logging settings
enabled = false
save_to_file = true
log_directory = "./conversation_logs"
include_timestamps = true
include_provider_info = true
include_system_prompt_uuid = true

# REDCap
[logging.redcap]
enabled = false
api_url = "https://redcap.institution.edu/api/"
project_id = "12345"
instrument_name = "conversation_data"
# API token should be stored in .secrets.toml under [REDCAP] section

# REDCap data structure configuration
[logging.redcap.fields]
# Participant information
participant_id_field = "participant_id"
consent_field = "consent_given"
demographics_event = "participants_arm_1"


[rag]
# RAG (Retrieval Augmented Generation) configuration
enabled = false
provider = "chroma"  # "chroma", "faiss", or "simple" (in-memory)
embedding_model = "text-embedding-ada-002"
embedding_provider = "openai"  # Use same provider as LLM for consistency

# Document processing
