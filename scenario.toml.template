# Research Scenario Configuration
# This file defines the experimental setup for this research session

[info]
name = "Name_this_Scenario"
description = "Experimental setup for studying conversation patterns with AI assistants"
version = "?.?.?"
created_date = "this-date"
scenario_id = "this-id"

[llm_provider]
# Single LLM provider configuration
name = "OPENROUTER"
# API key in .secrets.toml file
model = "o3-mini"
temperature = 0.7
max_tokens = 2000    # Current max for most models is 4096
description = "The model I picked"

[system_prompt]
# Reference to prompt stored in prompt database
prompt_id = "your-prompt-id"

[local_logging]
enabled = true
save_to_file = true
log_directory = "./conversation_logs"
include_timestamps = true
include_provider_info = true
include_system_prompt_uuid = true

[redcap_logging]
enabled = false
# API token should be stored in .secrets.toml under [REDCAP] section

[rag]
# RAG (Retrieval Augmented Generation) configurations TODO
enabled = false
provider = "chroma"  # "chroma", "faiss", or "simple" (in-memory)
embedding_model = "text-embedding-ada-002"
embedding_provider = "openai"  # Use same provider as LLM for consistency

# Document processing

