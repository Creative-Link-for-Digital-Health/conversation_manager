{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7144ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "from api_utils import load_api_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b09585d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API parameters and initialize client\n",
    "\n",
    "SECRETS_PATH = \"../.secrets.toml\"\n",
    "\n",
    "API_CALL_PARAMS = load_api_params(SECRETS_PATH)\n",
    "client = OpenAI(\n",
    "    base_url = API_CALL_PARAMS['API_URL'],\n",
    "    api_key = API_CALL_PARAMS['API_KEY']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "072fbd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_completion(model: str, messages: List[Dict[str, str]]) -> str:\n",
    "    \"\"\"Generate LLM output\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model, \n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2a19cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT = \"\"\"Hello. How are you.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fc6f837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm doing well, thank you for asking. I'm a large language model, so I don't have feelings like humans do, but I'm always happy to chat with you and help with any questions or topics you'd like to discuss. How about you? How's your day going?\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"You are a helpful assistant.\"\"\"},\n",
    "    {\"role\": \"user\", \"content\":f\"\"\"{USER_PROMPT}\"\"\"}\n",
    "]\n",
    "try:\n",
    "    model = API_CALL_PARAMS['MODEL']\n",
    "    LLM_output = generate_completion(model, messages)\n",
    "except Exception as e:\n",
    "    raise Exception(f\"Error generating completion: {e}\")\n",
    "\n",
    "print(LLM_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conversation-manager",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
