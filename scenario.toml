# Research Scenario Configuration
# This file defines the experimental setup for this research session

[info]
name = "Conversation Analysis Research"
description = "Experimental setup for studying conversation patterns with AI assistants"
version = "1.0.0"
created_date = "2025-05-24"
scenario_id = "150a8400-e39g-42d3-b7x6-q49653441020"

[llm_provider]
# Single LLM provider configuration
name = "OPENROUTER"
# API key in .secrets.toml file
model = "meta-llama/llama-4-scout:free"
#model = "superdrew100/llama3-abliterated"
#model = "o3-mini"
temperature = 0.7
max_tokens = 2000    # Current max for most models is 4096
description = "The model I picked"

[system_prompt]
# Reference to prompt stored in prompt database
prompt_id = "f1481049-3e06-4869-ac4c-9171b8d885d2"

[local_logging]
enabled = true
save_to_file = true
log_directory = "./conversation_logs"
include_timestamps = true
include_provider_info = true
include_system_prompt_uuid = true

[redcap_logging]
enabled = true
# API token should be stored in .secrets.toml under [REDCAP] section

[rag]
# RAG (Retrieval Augmented Generation) configurations TODO
enabled = false
provider = "chroma"  # "chroma", "faiss", or "simple" (in-memory)
embedding_model = "text-embedding-ada-002"
embedding_provider = "openai"  # Use same provider as LLM for consistency

# Document processing
